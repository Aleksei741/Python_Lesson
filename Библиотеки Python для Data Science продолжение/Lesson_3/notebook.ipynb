{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score, learning_curve\n",
    "from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(y_train_true, y_train_pred, y_test_true, y_test_pred):\n",
    "    print('TRAIN\\n\\n' + classification_report(y_train_true, y_train_pred))\n",
    "    print('TEST\\n\\n' + classification_report(y_test_true, y_test_pred))\n",
    "    print('CONFUSION MATRIX\\n')\n",
    "    print(pd.crosstab(y_test_true, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "DATASET_PATH = 'training_project_data.csv'\n",
    "PREP_DATASET_PATH = 'training_project_data_prep.csv'\n",
    "\n",
    "# output\n",
    "TRAIN_FULL_PATH = 'training_project_train_full.csv'\n",
    "TRAIN_PART_PATH = 'training_project_train_part_b.csv'\n",
    "TEST_PART_PATH = 'training_project_test_part.csv'\n",
    "\n",
    "SCALER_FILE_PATH = 'scaler.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PREP_DATASET_PATH)\n",
    "df_base = pd.read_csv(DATASET_PATH)\n",
    "\n",
    "TARGET_NAME = 'NEXT_MONTH_DEFAULT'\n",
    "BASE_FEATURE_NAMES = df_base.columns.drop(TARGET_NAME).tolist()\n",
    "NEW_FEATURE_NAMES = df.columns.drop([TARGET_NAME, 'ID'] + BASE_FEATURE_NAMES).tolist()\n",
    "\n",
    "NUM_FEATURE_NAMES = ['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "                     'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "\n",
    "CAT_FEATURE_NAMES = ['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "\n",
    "SELECTED_FEATURE_NAMES = NUM_FEATURE_NAMES + NEW_FEATURE_NAMES\n",
    "\n",
    "for colname in CAT_FEATURE_NAMES:\n",
    "    df[colname] = pd.Categorical(df[colname])\n",
    "    \n",
    "df[CAT_FEATURE_NAMES].dtypes\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "with open(SCALER_FILE_PATH, 'rb') as file:\n",
    "    scaler = pickle.load( file)\n",
    "    \n",
    "df_norm = df.copy()\n",
    "df_norm[NUM_FEATURE_NAMES] = scaler.fit_transform(df_norm[NUM_FEATURE_NAMES])\n",
    "\n",
    "df = df_norm.copy()\n",
    "\n",
    "X = df[SELECTED_FEATURE_NAMES]\n",
    "y = df[TARGET_NAME]\n",
    "\n",
    "X_s=X.copy()\n",
    "X_s[NUM_FEATURE_NAMES] = scaler.transform(X[NUM_FEATURE_NAMES])\n",
    "\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(X_s[SELECTED_FEATURE_NAMES],y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 51)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия - Максимизация правдоподобия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels_train1 = (labels_train == 1)\n",
    "Labels_test1 = (labels_test==1)\n",
    "\n",
    "LRC = LogisticRegression()\n",
    "LRC.fit(data_train, Labels_train1.astype(int))\n",
    "\n",
    "# Test \n",
    "y_train_pred = LRC.predict(data_train)\n",
    "y_test_pred= LRC.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ошибка LRC =  17.133333333333333 %\n"
     ]
    }
   ],
   "source": [
    "print('ошибка LRC = ',np.mean(np.abs(y_test_pred-Labels_test1.astype(int)))*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      5472\n",
      "           1       0.67      0.35      0.46      1528\n",
      "\n",
      "    accuracy                           0.82      7000\n",
      "   macro avg       0.76      0.65      0.68      7000\n",
      "weighted avg       0.80      0.82      0.80      7000\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90      2333\n",
      "           1       0.72      0.38      0.50       667\n",
      "\n",
      "    accuracy                           0.83      3000\n",
      "   macro avg       0.78      0.67      0.70      3000\n",
      "weighted avg       0.82      0.83      0.81      3000\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0                  0    1\n",
      "NEXT_MONTH_DEFAULT           \n",
      "0                   2234   99\n",
      "1                    415  252\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "get_classification_report(Labels_train1.astype(int), y_train_pred, Labels_test1.astype(int), y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM - максимизация зазора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "cSVM = svm.SVC()\n",
    "cSVM.fit(data_train, Labels_train1.astype(int))\n",
    "\n",
    "# Test \n",
    "predicteds = cSVM.predict(data_test)\n",
    "# Test \n",
    "y_train_pred = cSVM.predict(data_train)\n",
    "y_test_pred= cSVM.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ошибка SVM =  17.433333333333334 %\n"
     ]
    }
   ],
   "source": [
    "print('ошибка SVM = ',np.mean(np.abs(y_test_pred-Labels_test1.astype(int)))*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89      5472\n",
      "           1       0.68      0.32      0.43      1528\n",
      "\n",
      "    accuracy                           0.82      7000\n",
      "   macro avg       0.76      0.64      0.66      7000\n",
      "weighted avg       0.80      0.82      0.79      7000\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90      2333\n",
      "           1       0.72      0.35      0.47       667\n",
      "\n",
      "    accuracy                           0.83      3000\n",
      "   macro avg       0.78      0.66      0.68      3000\n",
      "weighted avg       0.81      0.83      0.80      3000\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0                  0    1\n",
      "NEXT_MONTH_DEFAULT           \n",
      "0                   2241   92\n",
      "1                    431  236\n"
     ]
    }
   ],
   "source": [
    "\n",
    "get_classification_report(Labels_train1.astype(int), y_train_pred, Labels_test1.astype(int), y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters, scoring ='f1_micro',)\n",
    "clf.fit(X_s, y)\n",
    "#GridSearchCV(estimator=SVC(),     param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
